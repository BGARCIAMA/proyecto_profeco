# Proyecto Quien es Quien (Profeco) ğŸ’°

# (MCD ITAM Primavera 2024)


## Autores ğŸ“š

| Nombre                     |  CU    | Correo ElectrÃ³nico | Usuario Github |
|----------------------------|--------|--------------------|----------------|
| Blanca E. GarcÃ­a Manjarrez | 118886 | bgarci11@itam.mx   |    BGARCIAMA   |
| IvÃ¡n GarcÃ­a                | ###### | xxxxxxxx@itam.mx   |   xxxxxxxxxxx  |
| Valeria DurÃ¡n              | ###### | xxxxxxxx@itam.mx   |   xxxxxxxxxxx  |
| Yuneri PÃ©rez Arellano      | 199813 | yperezar@itam.mx   |    YunPerez    |



# Contexto  ğŸ§ 
* Repositorio del proyecto de cÃ³mputo distribuido con informaciÃ³n del programa QuiÃ©n es QuiÃ©n en los Precios (QQP) recaba y difunde informaciÃ³n de precios de productos de consumo regular en el hogar, como alimentos, bebidas, productos de aseo personal y del hogar, medicinas, electrodomÃ©sticos y artÃ­culos de temporada para ofrecer informaciÃ³n que te permita tomar decisiones de compra mediante la comparaciÃ³n de precios.

* Para recabar los precios se visita una muestra de los principales establecimientos en cada una de las ciudades que forman parte del programa durante los cinco dÃ­as hÃ¡biles de la semana.

* Los precios que se muestran contienen la fecha en que fueron tomados, sin embargo se encuentran sujetos a cambios, ya que algunos establecimientos pueden variar sus precios mÃ¡s de una vez por dÃ­a, por lo que deben ser considerados como precios referencia.

# Objetivo del proyecto  ğŸ¯
* Utilizar tecnologÃ­as de gran escala vista en clase para analizar el dataset de QuiÃ©n es QuiÃ©n en los precios.

## Habilidades a evaluar ğŸ§‘â€ğŸ’»
* Uso de herramientas de gran escala.
* MetodologÃ­a vista en clase sobre limpieza de cÃ³digos
* SQL
* Pyspark

# Base de datos  âœ
* [QuiÃ©n es QuiÃ©n en los precios](https://datos.profeco.gob.mx/datos_abiertos/qqp.php). Registro histÃ³rico diario de mÃ¡s de 2,000 productos, a partir de 2015, en diversos establecimientos de la RepÃºblica Mexicana.
* Los dataset que se analizaron van del **2018-2024**.

# Estructura del Proyecto
## Parte A ğŸ“‘
* En esta parte se levantÃ³ un cluster en AWS con Hadoop y Pyspark 

* Elaboramos un ETL con el Cluster donde: 
* - Se subiÃ³ a S3 el archivo o archivos.
* - Se cargÃ³ el CSV en Spark.
* - Se guardÃ³ el CSV como parquet en S3, y se particionÃ³ por `catalogo` y `aÃ±o`.
* - Se cargÃ³ el parquet en Spark.
* - Y se hizÃ³ el anÃ¡lisis solicitado en las instrucciones [instrucciones-proyecto-parcial.md](instrucciones-proyecto-parcial.md).
 
## Parte B ğŸ“‘
Para esta parte se utilizÃ³ **Athena**. 

* - Se creÃ³ una base de datos `profeco_db` en Athena.
* - AsÃ­ como una tabla externa `profeco` dentro de la base de datos profeco_db.

## Requerimientos de Software herramientas recomendadas

1. [Cuenta de Github](https://github.com)
2. [VSCodeIDE](https://code.visualstudio.com)
3. [AWS](https://aws.amazon.com)


- Correr los scripts en el siguiente orden:
  1. bash/limpieza.sh
  2. bash/union.sh
  3. [Parte_A.ipynb] (Parte_A.ipynb)
  4. [Parte_B.ipynb] (Parte_B.ipynb)

# Entregables ğŸ’¯

* - ğŸ“¸ Un screenshot de cÃ³mo se guardÃ³ los archivos en S3, donde se ven las particiones.
* - ğŸ“¸ Un screenshot del dashboard del cluster, donde se ve el nombre, el id del cluster, el DNS, y el tiempo de ejecuciÃ³n.
* - ğŸ“¸ Un screenshot del JupyterHub, donde se vea la direcciÃ³n DNS (El URL).
* - ğŸ“¸ Un screenshot de la consola de Athena donde se ve la base de datos y la tabla de Profeco.
* - ğŸ““ Un cuaderno ejecutado con los resultados y el cÃ³digo con las preguntas y respuestas.

